{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 6.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "/Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
            "  from pandas.core import (\n",
            "/Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "\n",
        "# Partial CHATGPT Code\n",
        "def recursively_remove_rows(X, y, original_X, original_y, indices_removed=[]):\n",
        "    \"\"\"\n",
        "    Recursively tries to remove rows to improve or maintain the accuracy of a 1-NN classifier.\n",
        "\n",
        "    :param X: The current dataset features from which rows are being removed.\n",
        "    :param y: The current dataset labels from which corresponding rows are being removed.\n",
        "    :param original_X: The original dataset features used for testing the classifier.\n",
        "    :param original_y: The original dataset labels used for testing the classifier.\n",
        "    :param indices_removed: Indices of rows that have been removed so far.\n",
        "    :return: A tuple containing the pruned features and labels, and the indices of removed rows.\n",
        "    \"\"\"\n",
        "    # Base case: if X is empty or all rows have been attempted for removal\n",
        "    if len(X) == 0 or len(X) == len(indices_removed):\n",
        "        return X, y, indices_removed\n",
        "\n",
        "    for i in range(len(original_X)):\n",
        "        if i in indices_removed:  # Skip already removed rows\n",
        "            continue\n",
        "\n",
        "        # Create a training dataset excluding the current row\n",
        "        mask = np.array([index not in indices_removed and index != i for index in range(len(original_X))])\n",
        "        X_train = original_X[mask]\n",
        "        y_train = original_y[mask]\n",
        "\n",
        "        # Train a 1-NN classifier\n",
        "        knn = KNeighborsClassifier(n_neighbors=1)\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Test on the entire original dataset\n",
        "        predictions = knn.predict(original_X)\n",
        "        accuracy = accuracy_score(original_y, predictions)\n",
        "\n",
        "        # If accuracy is perfect, permanently remove the row and recurse\n",
        "        if accuracy == 1:\n",
        "            return recursively_remove_rows(X_train, y_train, original_X, original_y, indices_removed + [i])\n",
        "        #else:\n",
        "            #return len(X)\n",
        "\n",
        "    # If no row can be removed to maintain perfect accuracy\n",
        "    return X, y, indices_removed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first test it on a binary dataset with $d = 2, 4, 5, 6$ and the associated $n = 4, 16, 32, 64$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d=2: n_full=4, Avg. req. points for memorization n_avg=2.66, n_full/n_avg=1.5037593984962405\n",
            "d=4: n_full=16, Avg. req. points for memorization n_avg=9.04, n_full/n_avg=1.7699115044247788\n",
            "d=5: n_full=32, Avg. req. points for memorization n_avg=17.80, n_full/n_avg=1.797752808988764\n",
            "d=6: n_full=64, Avg. req. points for memorization n_avg=34.56, n_full/n_avg=1.8518518518518516\n"
          ]
        }
      ],
      "source": [
        "d_vals = [2, 4, 5, 6]\n",
        "num_of_class = 2\n",
        "\n",
        "for d in d_vals:\n",
        "    ns = []\n",
        "    for i in range(50):\n",
        "        # Permutate all combinations of features\n",
        "        X = np.array(list(product([0, 1], repeat=d)))\n",
        "        N, _ = X.shape\n",
        "        y = np.random.randint(num_of_class, size=(N, 1)).ravel()\n",
        "        X_final, y_final, rows_removed = recursively_remove_rows(X, y, X, y)\n",
        "    #print(rows_removed)\n",
        "        ns.append(N - len(rows_removed))    # Num of rows remaining\n",
        "    n_avg = np.mean(ns)\n",
        "\n",
        "    print(f\"d={d}: n_full={2**d}, Avg. req. points for memorization n_avg={n_avg:.2f}, n_full/n_avg={(2**d)/n_avg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that `n_full/n_avg` tends to 2 as d increases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d=2: n_full=4, Avg. req. points for memorization n_avg=3.14, n_full/n_avg=1.2738853503184713\n",
            "d=4: n_full=16, Avg. req. points for memorization n_avg=11.24, n_full/n_avg=1.4234875444839858\n",
            "d=5: n_full=32, Avg. req. points for memorization n_avg=21.82, n_full/n_avg=1.466544454628781\n",
            "d=6: n_full=64, Avg. req. points for memorization n_avg=42.84, n_full/n_avg=1.4939309056956114\n"
          ]
        }
      ],
      "source": [
        "d_vals = [2, 4, 5, 6]\n",
        "# Extend to multi-class\n",
        "num_of_class = 3\n",
        "for d in d_vals:\n",
        "    ns = []\n",
        "    for i in range(50):\n",
        "        X = np.array(list(product([0, 1], repeat=d)))\n",
        "        N, _ = X.shape\n",
        "        y = np.random.randint(num_of_class, size=(N, 1)).ravel()\n",
        "        X_final, y_final, rows_removed = recursively_remove_rows(X, y, X, y)\n",
        "    #print(rows_removed)\n",
        "        ns.append(N - len(rows_removed))\n",
        "    n_avg = np.mean(ns)\n",
        "\n",
        "    print(f\"d={d}: n_full={2**d}, Avg. req. points for memorization n_avg={n_avg:.2f}, n_full/n_avg={(2**d)/n_avg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As shown above, `n_full/n_avg` tends to 1.5 relatively quickly as d increases with 3 classes. This is expected, as $3/(3-1) = 1.5$ is the number of prediction bits in each parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 6.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "def find_split_points(x, labels):\n",
        "    \"\"\"Find if-else statements where the labels change\"\"\"\n",
        "    split_points = []\n",
        "    start = round(x[0],4)\n",
        "    split_points.append((-np.inf, start, labels[0]))\n",
        "\n",
        "    for i in range(1, len(x)):\n",
        "        # Check if the label changes from the previous point\n",
        "        if labels[i] != labels[i-1]:\n",
        "            #print(\"change at \", i)\n",
        "            end = round(x[i], 4)\n",
        "            split_points.append((start, end, labels[i-1]))\n",
        "            start = end\n",
        "    \n",
        "    split_points.append((start, np.Inf, labels[-1]))\n",
        "    return split_points\n",
        "\n",
        "def predict_if_else(x, split_points):\n",
        "    \"\"\"Predict the class for a given x based on split points.\"\"\"\n",
        "    x = float(x)\n",
        "    for i in split_points:\n",
        "        start = i[0]\n",
        "        end = i[1]\n",
        "        prediction = i[2]\n",
        "        #print(start, end, prediction)\n",
        "        if (x >= start) & (x < end):\n",
        "            return prediction\n",
        "\n",
        "def if_then_clauses(data, labels, weights = np.array([])):\n",
        "    \"\"\"Runs algorithm 8 and returns sorted_table and the thresholds (split_points)\"\"\"\n",
        "    clauses = []\n",
        "    n, d = data.shape\n",
        "    df = pd.DataFrame(data).copy()\n",
        "    if len(weights) == 0:\n",
        "        df['sum'] = df.sum(axis=1)\n",
        "    else:\n",
        "        df['sum'] = np.dot(df, weights)\n",
        "    df['label'] = labels\n",
        "    sorted_table = df.sort_values(by='sum').reset_index(drop=True)\n",
        "    #print(sorted_table[:100])\n",
        "\n",
        "    #print(sorted_table)\n",
        "    split_points = find_split_points(sorted_table['sum'].values, sorted_table['label'].values)\n",
        "\n",
        "    return sorted_table, split_points\n",
        "\n",
        "def eval_strategy(X, y, train_size, random_seed, tune=False, show_sorted=True, show_clauses=True):\n",
        "    \"\"\"Evaluate algorithm 8 results\"\"\"\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=random_seed)\n",
        "    #print(X_train.shape, X_test.shape)\n",
        "    if tune == False:\n",
        "        weights = np.array([])\n",
        "    else:\n",
        "        model_no_intercept = LogisticRegression(fit_intercept=False).fit(X_train, y_train)\n",
        "        # Model coefficients\n",
        "        weights = model_no_intercept.coef_[0]\n",
        "        \n",
        "    sorted_train, clauses = if_then_clauses(X_train, y_train, weights=weights)\n",
        "    sorted_test, _ = if_then_clauses(X_test, y_test, weights=weights)\n",
        "    #print(sorted_test)\n",
        "    predictions = [predict_if_else(x, clauses) for x in sorted_test['sum']]\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    if show_clauses:\n",
        "        print(\"if-else clauses: \")\n",
        "        print(clauses[1:-1])\n",
        "    print(\"Number of clauses: \", len(clauses[1:-1]))\n",
        "    if show_sorted==True:\n",
        "        print(\"Sorted_dataset: \")\n",
        "        print(sorted_test.head(20))\n",
        "    print(\"Prediction accuracy on test set: \", accuracy)\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we demonstrate how our algorithm works using a simple dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(-inf, 1, 0), (1, 3, 0), (3, 5, 1), (5, 7, 0), (7, inf, 1)]\n",
            "y_values: \n",
            "[0, 0, 1, 0, 1, 1]\n",
            "Predicted: \n",
            "[0, 0, 1, 0, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "# Example data\n",
        "x_values = [1, 2, 3, 5, 7, 9]\n",
        "labels = [0, 0, 1, 0, 1, 1]\n",
        "\n",
        "# Find the split points\n",
        "split_points = find_split_points(x_values, labels)\n",
        "test_x_values = [0, 2, 4, 6, 8, 10]\n",
        "predictions = [predict_if_else(x, split_points) for x in test_x_values]\n",
        "\n",
        "print(split_points)\n",
        "print(\"y_values: \")\n",
        "print(labels)\n",
        "print(\"Predicted: \")\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5w/gsy5p7694w76q69v5jwrqgl40000gn/T/ipykernel_56616/60707310.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  binary_iris['species'] = binary_iris['species'].map({'setosa': 0, 'versicolor': 1})\n"
          ]
        }
      ],
      "source": [
        "# Load the Iris dataset\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "binary_iris = iris[(iris['species'] == 'setosa') | (iris['species'] == 'versicolor')]\n",
        "\n",
        "# Convert 'species' to a binary variable: 'setosa' as 0, 'versicolor' as 1\n",
        "binary_iris['species'] = binary_iris['species'].map({'setosa': 0, 'versicolor': 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first apply algorithm 8 on the `iris` dataset with binary outcomes to minimize the number of if-else statements without tuning the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "if-else clauses: \n",
            "[(8.4, 11.5, 0), (11.5, 11.5, 1), (11.5, 11.6, 0)]\n",
            "Number of clauses:  3\n",
            "Sorted_dataset: \n",
            "    sepal_length  sepal_width  petal_length  petal_width   sum  label\n",
            "0            4.4          3.2           1.3          0.2   9.1      0\n",
            "1            4.8          3.0           1.4          0.3   9.5      0\n",
            "2            4.9          3.1           1.5          0.1   9.6      0\n",
            "3            4.9          3.1           1.5          0.2   9.7      0\n",
            "4            4.6          3.4           1.4          0.3   9.7      0\n",
            "5            5.0          3.0           1.6          0.2   9.8      0\n",
            "6            5.1          3.3           1.7          0.5  10.6      0\n",
            "7            5.0          2.3           3.3          1.0  11.6      1\n",
            "8            5.1          2.5           3.0          1.1  11.7      1\n",
            "9            5.7          4.4           1.5          0.4  12.0      0\n",
            "10           5.2          2.7           3.9          1.4  13.2      1\n",
            "11           5.6          2.9           3.6          1.3  13.4      1\n",
            "12           5.8          2.7           3.9          1.2  13.6      1\n",
            "13           5.8          2.7           4.1          1.0  13.6      1\n",
            "14           5.7          2.9           4.2          1.3  14.1      1\n",
            "15           6.1          2.8           4.0          1.3  14.2      1\n",
            "16           6.2          2.9           4.3          1.3  14.7      1\n",
            "17           6.0          2.7           5.1          1.6  15.4      1\n",
            "18           6.6          3.0           4.4          1.4  15.4      1\n",
            "19           6.7          3.0           5.0          1.7  16.4      1\n",
            "Prediction accuracy on test set:  0.35\n"
          ]
        }
      ],
      "source": [
        "# Without applying weights\n",
        "X = binary_iris.iloc[:, :-1]\n",
        "y = binary_iris.iloc[:, -1]\n",
        "\n",
        "# Generating a dataset for the AND function\n",
        "# Define the inputs and the corresponding outputs for AND function\n",
        "# inputs = [(0, 0), (0, 1), (1, 1), (1, 0)]\n",
        "# outputs = [0, 0, 1, 0]\n",
        "\n",
        "# df_and = pd.DataFrame(inputs, columns=['x1', 'x2'])\n",
        "# df_and['y'] = outputs\n",
        "\n",
        "# X = df_and.iloc[:, :-1]\n",
        "# y = df_and.iloc[:, -1]\n",
        "\n",
        "eval_strategy(X, y, 0.8, random_seed=3, tune=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we try to tune the weights using logistic regression without the intercept:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "if-else clauses: \n",
            "[(-5.365, 2.1947, 0)]\n",
            "Number of clauses:  1\n",
            "Sorted_dataset: \n",
            "    sepal_length  sepal_width  petal_length  petal_width       sum  label\n",
            "0            5.7          4.4           1.5          0.4 -5.075433      0\n",
            "1            4.6          3.4           1.4          0.3 -3.506192      0\n",
            "2            4.4          3.2           1.3          0.2 -3.440568      0\n",
            "3            4.9          3.1           1.5          0.1 -3.180065      0\n",
            "4            4.9          3.1           1.5          0.2 -3.090462      0\n",
            "5            4.8          3.0           1.4          0.3 -3.028316      0\n",
            "6            5.0          3.0           1.6          0.2 -2.781923      0\n",
            "7            5.1          3.3           1.7          0.5 -2.766738      0\n",
            "8            5.1          2.5           3.0          1.1  1.627045      1\n",
            "9            5.6          2.9           3.6          1.3  2.294220      1\n",
            "10           5.0          2.3           3.3          1.0  2.491092      1\n",
            "11           5.8          2.7           3.9          1.2  3.031837      1\n",
            "12           6.1          2.8           4.0          1.3  3.064610      1\n",
            "13           5.8          2.7           4.1          1.0  3.272914      1\n",
            "14           5.2          2.7           3.9          1.4  3.463903      1\n",
            "15           6.6          3.0           4.4          1.4  3.502981      1\n",
            "16           6.2          2.9           4.3          1.3  3.512351      1\n",
            "17           5.7          2.9           4.2          1.3  3.512927      1\n",
            "18           6.7          3.0           5.0          1.7  4.990495      1\n",
            "19           6.0          2.7           5.1          1.6  5.827661      1\n",
            "Prediction accuracy on test set:  0.45\n"
          ]
        }
      ],
      "source": [
        "eval_strategy(X, y, 0.8, random_seed=3, tune=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that we reduced the number of thresholds from 3 to 1 while increasing our prediction accuracy on the test set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Strategy 1: 1 if-else statement\n",
        "### Predict majority class for all rows\n",
        "# def predict_majority_class(X, y):\n",
        "#     majority_class = y.mode()[0]\n",
        "#     predictions = np.full(len(X), majority_class, dtype=int)\n",
        "\n",
        "#     accuracy = accuracy_score(predictions, y)\n",
        "\n",
        "#     return predictions, accuracy\n",
        "\n",
        "### Strategy 1: sum of xs > b\n",
        "# def predict_sum(X, y):\n",
        "#     max_b = X.shape[1]\n",
        "#     best_acc = 0\n",
        "#     best_b = 0\n",
        "#     best_pred = []\n",
        "#     for i in range(max_b):\n",
        "#         feature_sum = X.sum(axis=1)\n",
        "#         # Predict 1 if the sum is greater than 'b', else 0\n",
        "#         predictions = (feature_sum > i).astype(int)\n",
        "\n",
        "#         accuracy_temp = accuracy_score(predictions, y)\n",
        "#         if accuracy_temp > best_acc:\n",
        "#             best_acc = accuracy_temp\n",
        "#             best_b = i\n",
        "#             best_pred = predictions\n",
        "    \n",
        "#     return predictions, best_acc, best_b\n",
        "\n",
        "# def do_algorithm_8(X, y, weights = np.array([])):\n",
        "#     threshold = 0\n",
        "#     n, d = X.shape\n",
        "    \n",
        "#     table = pd.DataFrame()\n",
        "#     if len(weights) == 0:\n",
        "#         table['sum_x'] = X.sum(axis=1)\n",
        "#     else:\n",
        "#         table['sum_x'] = np.dot(X, weights)\n",
        "#     table['y'] = y\n",
        "#     table_sorted = table.sort_values(by=\"sum_x\")\n",
        "#     #print(table_sorted)\n",
        "#     print(table_sorted)\n",
        "\n",
        "#     #class_ = np.zeros(n)\n",
        "#     # for i in range(n):\n",
        "#     #     y_row = table_sorted.iloc[i, 1]\n",
        "#     #     # if y is not 0, then \n",
        "#     #     if table_sorted.iloc[i, 1] != 0:\n",
        "#     #         class_[i] = y_row\n",
        "#     #         threshold += 1\n",
        "#     ys_sorted = table_sorted.iloc[:, -1].values\n",
        "#     threshold = 0\n",
        "    \n",
        "#     for i in range(len(ys_sorted) - 1):\n",
        "#         if ys_sorted[i] != ys_sorted[i + 1]:\n",
        "#             # Increment the counter if a change is found\n",
        "#             threshold += 1\n",
        "            \n",
        "#     # num of threshold comparisons = num of if-else statements \n",
        "#     #print(\"Threshold\", threshold)\n",
        "    \n",
        "#     minthres = np.log2(threshold + 1)\n",
        "#     mec = int((minthres * (d+1)) + (minthres + 1))\n",
        "\n",
        "#     return threshold, minthres, mec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we try our algorithms on the `xor` dataset and the famous `titanic` dataset (only binary explanatory variables are retained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  y\n",
              "0   0   0  0\n",
              "1   0   1  1\n",
              "2   1   0  1\n",
              "3   1   1  0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generating a dataset for the Xor function\n",
        "# Define the inputs and the corresponding outputs for XOR function\n",
        "inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
        "outputs = [0, 1, 1, 0]\n",
        "\n",
        "# Create a DataFrame\n",
        "df_xor = pd.DataFrame(inputs, columns=['x1', 'x2'])\n",
        "df_xor['y'] = outputs\n",
        "\n",
        "df_xor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "if-else clauses: \n",
            "[(1, 2, 1)]\n",
            "Number of clauses:  1\n",
            "Prediction accuracy on test set:  0.0\n"
          ]
        }
      ],
      "source": [
        "X = df_xor.iloc[:, :-1]\n",
        "y = df_xor.iloc[:, -1]\n",
        "\n",
        "eval_strategy(X, y, train_size=0.8, random_seed=12, tune=False, show_sorted=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "if-else clauses: \n",
            "[(0.0, 0.0, 1)]\n",
            "Number of clauses:  1\n",
            "Prediction accuracy on test set:  1.0\n"
          ]
        }
      ],
      "source": [
        "X = df_xor.iloc[:, :-1]\n",
        "y = df_xor.iloc[:, -1]\n",
        "\n",
        "eval_strategy(X, y, train_size=0.8, random_seed=12, tune=True, show_sorted=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "      <th>class</th>\n",
              "      <th>who</th>\n",
              "      <th>adult_male</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alive</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
              "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
              "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
              "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
              "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
              "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
              "\n",
              "     who  adult_male deck  embark_town alive  alone  \n",
              "0    man        True  NaN  Southampton    no  False  \n",
              "1  woman       False    C    Cherbourg   yes  False  \n",
              "2  woman       False  NaN  Southampton   yes   True  \n",
              "3  woman       False    C  Southampton   yes  False  \n",
              "4    man        True  NaN  Southampton    no   True  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the Titanic dataset\n",
        "titanic = sns.load_dataset('titanic')\n",
        "titanic.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>adult_male</th>\n",
              "      <th>who</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  sibsp  adult_male  who  alone\n",
              "0         0      1           1    1      0\n",
              "1         1      1           0    0      0\n",
              "2         1      0           0    0      1\n",
              "3         1      1           0    0      0\n",
              "4         0      0           1    1      1"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = titanic.loc[:, [\"survived\", \"sibsp\", \"adult_male\", \"who\", \"alone\"]]\n",
        "# Convert boolean columns to integers\n",
        "df = pd.get_dummies(df, columns=[\"adult_male\", \"who\", \"alone\"], drop_first=True)\n",
        "df = df.drop(\"who_woman\", axis=1)\n",
        "\n",
        "# Convert boolean columns to integers (0s and 1s)\n",
        "df['adult_male'] = df['adult_male_True'].astype(int)\n",
        "df['who'] = df['who_man'].astype(int)\n",
        "df['alone'] = df['alone_True'].astype(int)\n",
        "\n",
        "# Drop the original boolean columns if they are no longer needed\n",
        "df.drop(columns=['adult_male_True', 'who_man', 'alone_True'], inplace=True)\n",
        "\n",
        "# Now df has the columns with 0s and 1s instead of True/False.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of clauses:  225\n",
            "Sorted_dataset: \n",
            "    sibsp  adult_male  who  alone  sum  label\n",
            "0       0           0    0      0    0      1\n",
            "1       0           0    0      0    0      0\n",
            "2       0           0    0      0    0      1\n",
            "3       0           0    0      0    0      0\n",
            "4       0           0    0      0    0      1\n",
            "5       0           0    0      0    0      1\n",
            "6       0           0    0      0    0      1\n",
            "7       0           0    0      0    0      1\n",
            "8       0           0    0      0    0      1\n",
            "9       0           0    0      0    0      0\n",
            "10      0           0    0      0    0      1\n",
            "11      1           0    0      0    1      1\n",
            "12      0           0    0      1    1      1\n",
            "13      0           0    0      1    1      1\n",
            "14      1           0    0      0    1      1\n",
            "15      0           0    0      1    1      0\n",
            "16      0           0    0      1    1      1\n",
            "17      1           0    0      0    1      1\n",
            "18      1           0    0      0    1      1\n",
            "19      1           0    0      0    1      1\n",
            "Prediction accuracy on test set:  0.48044692737430167\n"
          ]
        }
      ],
      "source": [
        "X = df.iloc[:, 1:]\n",
        "y = df.iloc[:, 0]\n",
        "\n",
        "eval_strategy(X, y, train_size=0.8, random_seed=12, tune=False, show_clauses=False, show_sorted=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of clauses:  198\n",
            "Prediction accuracy on test set:  0.5586592178770949\n"
          ]
        }
      ],
      "source": [
        "eval_strategy(X, y, train_size=0.8, random_seed=12, tune=True, show_clauses=False, show_sorted=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the `XOR` dataset, we observe that tuning the weights did not reduce the number of clauses but improved the overall accuracy significantly. \n",
        "\n",
        "Using the binary features in the titanic dataset, we see that the prediciton accuracy still improved when we decided to tune our weights, but the clauses are messed up due to violations of the functional assumption of supervised machine learning: there are many people with the same features ($x_i = x_j$) but different survival statuses ($f(x_i) \\neq f(x_j)$). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CHATGPT Code\n",
        "def create_random_binary_dataset(num_samples=100, num_features=3, random_state=None):\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "    \n",
        "    # Generate random binary values for the features\n",
        "    features = np.random.randint(2, size=(num_samples, num_features))\n",
        "    \n",
        "    # Generate a random binary target variable\n",
        "    target = np.random.randint(2, size=(num_samples, 1))\n",
        "    \n",
        "    # Create a DataFrame\n",
        "    data = pd.DataFrame(features, columns=[f'x{i+1}' for i in range(num_features)])\n",
        "    data['y'] = target\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# When n >> d (n=100, d=3)\n",
        "df_long = create_random_binary_dataset(num_samples = 100, num_features = 50,random_state=1)\n",
        "\n",
        "# When n = d (n=d=100)\n",
        "df_equal = create_random_binary_dataset(num_samples = 100, num_features = 100, random_state=1)\n",
        "\n",
        "# When n << d (n=3, d=100)\n",
        "df_wide = create_random_binary_dataset(num_samples = 50, num_features = 100, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results with no weight tuning:\n",
            "--------------------------------------------------\n",
            "Number of clauses:  33\n",
            "Prediction accuracy on test set:  0.55\n",
            "Results with weight tuning:\n",
            "--------------------------------------------------\n",
            "Number of clauses:  13\n",
            "Prediction accuracy on test set:  0.5\n",
            "Results with no weight tuning:\n",
            "--------------------------------------------------\n",
            "Number of clauses:  35\n",
            "Prediction accuracy on test set:  0.6\n",
            "Results with weight tuning:\n",
            "--------------------------------------------------\n",
            "Number of clauses:  1\n",
            "Prediction accuracy on test set:  0.7\n",
            "Results with no weight tuning:\n",
            "--------------------------------------------------\n",
            "Number of clauses:  22\n",
            "Prediction accuracy on test set:  0.6\n",
            "Results with weight tuning:\n",
            "--------------------------------------------------\n",
            "Number of clauses:  1\n",
            "Prediction accuracy on test set:  0.5\n"
          ]
        }
      ],
      "source": [
        "for df in [df_long, df_equal, df_wide]:\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1]\n",
        "    print(\"Results with no weight tuning:\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    eval_strategy(X, y, train_size=0.8, random_seed=1, show_sorted=False, show_clauses=False)\n",
        "    print(\"Results with weight tuning:\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    eval_strategy(X, y, train_size=0.8, random_seed=1, tune=True, show_sorted=False, show_clauses=False)\n",
        "    # threshold, minthres, mec = do_algorithm_8(df)\n",
        "    # print(\"Num of if-else statements: \", threshold)\n",
        "    # print(\"Minimum amount of thresholds: \", minthres)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here not only do we change the $n$ and $d$ to make a long, wide and square data matrix, we also try to see if tuning the weights improve our algorithm performance on a completely random dataset. We observe no significant differences in terms of the prediction accuracy with or without weights tuning. This is expected as our dataset is completely random with no underlying patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 6.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import zlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_random_string(length=1024):\n",
        "    # Using a set of characters to generate the random string\n",
        "    chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'\n",
        "    return ''.join(random.choice(chars) for _ in range(length))\n",
        "\n",
        "def compress_string(input_string):\n",
        "    # Compressing the input string using gzip\n",
        "    compressed_data = zlib.compress(input_string.encode('utf-8'))\n",
        "    return compressed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "botFX8G13t44fDMyOyKZ\n"
          ]
        }
      ],
      "source": [
        "# An example of char string\n",
        "print(generate_random_string()[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# string lengths to test\n",
        "string_lengths = [200, 1000, 10000, 100000]\n",
        "\n",
        "results = []\n",
        "\n",
        "# Loop through each string length\n",
        "for length in string_lengths:\n",
        "    random_string = generate_random_string(length)\n",
        "    compressed_string = compress_string(random_string)\n",
        "    # Calculate the compression ratio\n",
        "    compression_ratio = len(compressed_string) / len(random_string.encode('utf-8'))\n",
        "    results.append({\"String Length\": length, \"Compression Ratio\": compression_ratio})\n",
        "\n",
        "# Convert the results list to a DataFrame\n",
        "compression_summary = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>String Length</th>\n",
              "      <th>Compression Ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200</td>\n",
              "      <td>0.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000</td>\n",
              "      <td>0.7790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10000</td>\n",
              "      <td>0.7527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100000</td>\n",
              "      <td>0.7519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   String Length  Compression Ratio\n",
              "0            200             0.9250\n",
              "1           1000             0.7790\n",
              "2          10000             0.7527\n",
              "3         100000             0.7519"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compression_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Typically, we expect the compression ratio of applying a lossless compression on random string to be close to 1 or even exceeds 1. This is because long random strings have very high entropy, and our lossless compression algorithm struggles to find redundant or repeating patterns in our string. However, here we got a much lower number for long random strings, potentially because 1. the cost of overheads is relatively smaller and 2. there are more opportunities for pattern detection for larger strings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "itRzLu1UH4c_"
      },
      "source": [
        "# Question 8.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "12 + min(12, 3) + min(12, 3) = 18 bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3 + 4 + 4 = 11 bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "can memorize 18 rows and b) can memorize 11 rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$log_2 4 = 2$. \n",
        "\n",
        "$18 // 2 = 9$ and $11 // 2 = 5$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 8.2 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Alt text](Untitled.png \"The Two NN Architechtures\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 8.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimation of Total Sensory Experience"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assume the human eye is a camera with $576$ megapixels. Each pixel has $24$ bits of color depth ($8$ bits for each of the red, green, and blue channels). Therefore the information per second can be calculated as $576 \\times 24 = 13,824$ megabits per second. This is $1.4 \\times 10^{10}$ bits\n",
        "\n",
        "Then, the total seconds in 24 years assuming 16 hours of wakefulness per day is around $10^9$ seconds. Thus the total amount of information of visual experience in 24 years is $1.4 \\times 10^{19}$ bits. Similar analysis can be done for auditory information. Let total visual experience be $X$ and total sensory experience be $Y$ and assuming complete independence, the final capacity is $H(X) + H(Y) \\approx 3 \\times 10^{19}$ bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How much have we memorized?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's assume on average humans remember only 20% of auditory and visual information. Then that would be $6 * 10^{18}$ bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Capacity of human brain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can ignore the bias term due to the great size of the number of neurons: MEC of the brain is $10^{11} \\times 1000 = 10^{14}$ bits. Still this shows that our brain would be  full if we memorize 20% of all input information, as $10^{14} << 10^{18}$ bits that we estimated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Shakespeare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we assume 6 bytes per word including spaces and punctuations, Shakespeare's collected works include a bit under 1 million words of texts in total. Then assuming there is no mutual information contained between words, the total number of information is additive: $6 \\times 1,000,000 = 6 \\text{mb}$ of info ([source](https://nlp.stanford.edu/IR-book/html/htmledition/an-example-information-retrieval-problem-1.html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use algorithm 8 and train it on a random dataset with c equi-distributed classes. Then divide the number of thresholds generated by the number of instances memorized. We should expect to see $\\frac{c}{c-1}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def do_algorithm_8_multiclass(df, k):\n",
        "#     \"\"\"\n",
        "#     Assumes classes are indexed as 0, 1, 2....k-1 where k is the number of classes\n",
        "#     \"\"\"\n",
        "#     threshold = 0\n",
        "#     n = df.shape[0]\n",
        "#     d = df.shape[1] - 1   # number of columns\n",
        "    \n",
        "#     table = pd.DataFrame()\n",
        "#     table['sum_x'] = df.iloc[:, :-1].sum(axis=1)\n",
        "#     table['y'] = df.y\n",
        "#     table_sorted = table.sort_values(by=\"sum_x\")\n",
        "#     #print(table_sorted)\n",
        "\n",
        "#     class_ = np.zeros(n)\n",
        "#     for i in range(n):\n",
        "#         y_row = table_sorted.iloc[i, 1]\n",
        "#         # if y is not 0, then \n",
        "#         if table_sorted.iloc[i, 1] != 0:\n",
        "#             class_[i] = y_row\n",
        "#             threshold += 1\n",
        "    \n",
        "#     # num of threshold comparisons = num of if-else statements \n",
        "#     #print(\"Threshold\", threshold)\n",
        "   \n",
        "#     minthres =  math.log(threshold + 1, k)\n",
        "\n",
        "#     mec = int((minthres * (d+1)) + (minthres + 1))\n",
        "\n",
        "#     return threshold, minthres, mec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## c) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar argument as above, except we should see $1$ as the resulting number, as $\\frac{c}{c-1}$ equals $1$ as c tends to $\\infty$ when we have regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def do_algorithm_8_reg (df): \n",
        "#     \"\"\"\n",
        "#     Runs algorithm 8 for regression tasks\n",
        "#     \"\"\"\n",
        "#     threshold = 0\n",
        "#     n = df.shape[0]\n",
        "#     d = df.shape[1] - 1   # number of columns\n",
        "    \n",
        "#     table = pd.DataFrame()\n",
        "#     table['sum_x'] = df.iloc[:, :-1].sum(axis=1)\n",
        "#     table['y'] = df.y\n",
        "#     table_sorted = table.sort_values(by=\"sum_x\")\n",
        "#     print(table_sorted)\n",
        "\n",
        "# def generate_reg_data(n, d):\n",
        "#     \"\"\"\n",
        "#     Generates a completely random regression dataset.\n",
        "#     \"\"\"\n",
        "#     # Generate random features\n",
        "#     X = np.random.randn(n, d)\n",
        "#     coefficients = np.random.randn(d, 1)\n",
        "    \n",
        "#     # Generate noise\n",
        "#     noise = np.random.randn(n, 1)\n",
        "    \n",
        "#     # Generate target variable y = X * coefficients + noise\n",
        "#     y = X @ coefficients + noise\n",
        "#     y = y.flatten()\n",
        "#     df = pd.DataFrame(X, columns=[f'x_{i}' for i in range(1, d+1)])\n",
        "    \n",
        "#     # Add the target variable column to the DataFrame\n",
        "#     df['y'] = y\n",
        "    \n",
        "#     return df\n",
        "\n",
        "# # Example usage\n",
        "# n = 100  # Number of samples\n",
        "# d = 5    # Number of features\n",
        "# df = generate_reg_data(n, d)\n",
        "# df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 9.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SEE OTHER NOTEBOOK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "162b6b064e165ad366d1bd4cdc631c4691b039cb551eb2d47403b16e997dbe09"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0195224c08974231bd97b1e752fd4256": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53d05687d586488f8d81b6c5a5543f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7090803403484b6ca88f6f38d33b2381": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "993e8ea15eae4969a5343926beb7dbc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e489882b66a54e46bc0a0b508d6710e7",
              "IPY_MODEL_a43b880438ee4d9790ee9834f651e8d8",
              "IPY_MODEL_c509b532fce14526be705ff955a18227"
            ],
            "layout": "IPY_MODEL_e420bb4c91d146728ff290a013d25530"
          }
        },
        "a43b880438ee4d9790ee9834f651e8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9746d12c09542cba265ef4a8bf66c01",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc7bca1e98d34b03b2e92765e049b5d9",
            "value": 170498071
          }
        },
        "bc7bca1e98d34b03b2e92765e049b5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c509b532fce14526be705ff955a18227": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7090803403484b6ca88f6f38d33b2381",
            "placeholder": "",
            "style": "IPY_MODEL_53d05687d586488f8d81b6c5a5543f0a",
            "value": " 170498071/170498071 [00:14&lt;00:00, 13161925.48it/s]"
          }
        },
        "c79523930ad24c80b93e44d2237f2395": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9746d12c09542cba265ef4a8bf66c01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e420bb4c91d146728ff290a013d25530": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e489882b66a54e46bc0a0b508d6710e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c79523930ad24c80b93e44d2237f2395",
            "placeholder": "",
            "style": "IPY_MODEL_0195224c08974231bd97b1e752fd4256",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
